{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "There was a thought back to my playing days that revolved around a quote by or about Wayne Gretzky that I'll do my best not butcher. It involved why he would take such a long first shift, or why his coach would double shift him on his first shift. It was so he could catch his \"Second Wind\", meaning that since he was tired after his first shift, he would catch his breathe, and there after would play better.\n",
    "\n",
    "The coach or Wayne would do this intentionally to get into the game and play better throughout the rest of the game. I want to see if this has any creedence or is just some myth that a coach made up to play his best player more often at the beginning of the game."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis\n",
    "\n",
    "Null Hypothesis: The first shift length for a player has no impact on the players goal output for the game. \n",
    "\n",
    "Alternative Hypthesis: A longer first shift improves the player goals for that game."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measurement:\n",
    "There are plenty of ways to measure effect on a game, but we are going to keep it limited to goals for that game and then move on to other metrics later on. \n",
    "\n",
    "To consider a shift \"long\" we are going to calculate the average shift length for all players in the league. View how that fits on the distribution. \n",
    "\n",
    "Then to consider a first shift long for each game for that player we are going to compare it to the average length. We will place the player in a bin (Long shift, Not Long Shift).\n",
    "\n",
    "Then compare the goals for all players over a season to see if the first shift had an impact on goals for, for a game. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias/Assumptions\n",
    "Outcomes/Goals: We know that all players are not the same, for example Conner McDavid is going to be more valuable during his shifts and is going to have more shifts than a below average player in the NHL, but the hope is that by viewing the entire NHL population as a whole we are going to average out outliers like Connor McDavid and his less talented counter parts.\n",
    "\n",
    "Inputs/Shifts: \n",
    "\n",
    "I had quite a few thoughts around this one:\n",
    "The first one being is a shift long if it is just higher than the average or is there some point that makes a shift long? If say for example the average shift is 40 seconds should a shift that is 41 seconds be considered long? To help keep the experiment simple the first attempt I'm going to consider it as yes, that shift is \"long\". In the future, an adaptation might be to only include shifts that are \"long\" to be 1 standard deviation from the average shift. Roughly speaking, in a normal distribution, a shift that is 1 s.d. above the mean is equivalent to the 84th percentile. Now thats a long shift. \n",
    "\n",
    "Another thought I had from my playing days was that I took a really short first shift and then my second shift would be \"long\" to help me get into the game. But for the sake of the experiment we're only going to focus on the first shift. The thought here being that in an NHL game, if you are a forward on the 4th line you second shift might not occur until, (40 (sec) * 4 (# of lines) * 2 (Iterations/Shifts) ) = 320 Seconds / 60 Sec = 5.3 Minutes into the game. Within that time so many \"events\" (Goals, powerplays, penalities against, TV Timeouts) might occur to affect how shifts might be distributed. \n",
    "\n",
    "Finally, we are only going to consider the first shift of the first period. NHL intermissions are rather long (18 minutes), but we are going to assume that the players are into the game at that point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Considerations\n",
    "Do we want to consider removing outliers from the data, the top and bottom percent of shifts. \n",
    "\n",
    "Do we want to consider standarizining the shifts? So that they are easier to view if they are above average?\n",
    "\n",
    "Do we want to consider one stD away from the mean to be higher than average?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type: Diff from Diff\n",
    "Since we have a category of short versus long first shift, I am going to do a diff from diff. My assumption is that the population of players and their outcomes are pretty standard and even. And the only difference is going to be their first shift length. Then I can compare the outcomes (Goals) to see if first shift length has an impact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type: Linear Regression\n",
    "After I have decided in the null hypothesis is true or not, I am going to run a linear regression to see the first shift affects the likelihood of a goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hockey_scraper as hs\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift2015 = pd.read_csv(\"../hockey_scraper_data/csvs/nhl_shifts_20152016.csv\")\n",
    "pbp2015 = pd.read_csv(\"../hockey_scraper_data/csvs/nhl_pbp_20152016.csv\")\n",
    "shift2016 = pd.read_csv(\"../hockey_scraper_data/csvs/nhl_shifts_20162017.csv\")\n",
    "pbp2016 = pd.read_csv(\"../hockey_scraper_data/csvs/nhl_pbp_20162017.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show full output on DataFrame Rows\n",
    "pd.set_option('display.max_rows', 500)\n",
    "# Show full number on describes\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift2015[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift2015RowNumber = shift2015.shape[0]\n",
    "shift2015.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbp2015[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbp2015RowNumber = pbp2015.shape[0]\n",
    "pbp2015.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift2016RowNumber = shift2016.shape[0]\n",
    "shift2016.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbp2016RowNumber = pbp2016.shape[0]\n",
    "pbp2016.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift2015.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbp2015.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important metrics for our experiment:\n",
    "\n",
    "shift data:\n",
    "Need every first shift for every player in that that. (For every game (gameID), find the the first shift (Unnamed: 0) for every player (playerId). Add that player to the category \"Long\" or \"Not Long\" category\n",
    "\n",
    "pbp2015:\n",
    "For every game, and every player, calculate if they scored (Go through every PBP entry for every game, and every player).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename column \"Unnamed: 0\" to shift_Id\n",
    "shift2015.rename(columns = {\"Unnamed: 0\" : \"Shift_Id\"}, inplace = True)\n",
    "shift2016.rename(columns = {\"Unnamed: 0\" : \"Shift_Id\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename column \"Unnamed: 0\" to Pbp_Id\n",
    "pbp2015.rename(columns = {\"Unnamed: 0\" : \"Pbp_Id\"}, inplace = True)\n",
    "pbp2016.rename(columns = {\"Unnamed: 0\" : \"Pbp_Id\"}, inplace = True)\n",
    "\n",
    "# Convert player_ids to ints not floats\n",
    "\n",
    "# Replace NaN and infinite values with a suitable value (e.g. 0)\n",
    "pbp2015['p1_ID'].replace([np.inf, -np.inf, np.nan], 0, inplace=True)\n",
    "pbp2016['p1_ID'].replace([np.inf, -np.inf, np.nan], 0, inplace=True)\n",
    "pbp2015['p1_ID'] = pbp2015['p1_ID'].astype(int)\n",
    "pbp2016['p1_ID'] = pbp2016['p1_ID'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Unwanted Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Drop columns\n",
    "# Need to keep goalie IDs to drop the goal from the Shift Data\n",
    "pbp2015.drop(columns = {'Description','Type','Ev_Team', 'Home_Zone', 'Away_Team', 'Home_Team',\n",
    "       'Time_Elapsed', 'Seconds_Elapsed', 'Strength', 'Ev_Zone','awayPlayer1', 'awayPlayer1_id',\n",
    "       'awayPlayer2', 'awayPlayer2_id', 'awayPlayer3', 'awayPlayer3_id',\n",
    "       'awayPlayer4', 'awayPlayer4_id', 'awayPlayer5', 'awayPlayer5_id',\n",
    "       'awayPlayer6', 'awayPlayer6_id', 'homePlayer1', 'homePlayer1_id',\n",
    "       'homePlayer2', 'homePlayer2_id', 'homePlayer3', 'homePlayer3_id',\n",
    "       'homePlayer4', 'homePlayer4_id', 'homePlayer5', 'homePlayer5_id',\n",
    "       'homePlayer6', 'homePlayer6_id', 'Away_Players', 'Home_Players',\n",
    "       'Away_Score', 'Home_Score', 'xC', 'yC', 'Home_Coach',\n",
    "       'Away_Coach'}, inplace = True)\n",
    "pbp2016.drop(columns = {'Description','Type','Ev_Team', 'Home_Zone', 'Away_Team', 'Home_Team',\n",
    "       'Time_Elapsed', 'Seconds_Elapsed', 'Strength', 'Ev_Zone','awayPlayer1', 'awayPlayer1_id',\n",
    "       'awayPlayer2', 'awayPlayer2_id', 'awayPlayer3', 'awayPlayer3_id',\n",
    "       'awayPlayer4', 'awayPlayer4_id', 'awayPlayer5', 'awayPlayer5_id',\n",
    "       'awayPlayer6', 'awayPlayer6_id', 'homePlayer1', 'homePlayer1_id',\n",
    "       'homePlayer2', 'homePlayer2_id', 'homePlayer3', 'homePlayer3_id',\n",
    "       'homePlayer4', 'homePlayer4_id', 'homePlayer5', 'homePlayer5_id',\n",
    "       'homePlayer6', 'homePlayer6_id', 'Away_Players', 'Home_Players',\n",
    "       'Away_Score', 'Home_Score', 'xC', 'yC', 'Home_Coach',\n",
    "       'Away_Coach'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Play by Play 2015\", pbp2015.shape)\n",
    "print(\"Play by Play 2016\", pbp2016.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to remove Goalies from the shift Data\n",
    "# Their shifts will skew the data\n",
    "\n",
    "# Find all the unique goalie IDs from the Home and Away Goalie Ids in the Play By Play Data\n",
    "# Union will drop duplicates\n",
    "allGoalies2015 = np.union1d( pd.unique(pbp2015[\"Away_Goalie_Id\"]), pd.unique(pbp2015[\"Home_Goalie_Id\"]))\n",
    "# Drop the empty fields\n",
    "allGoalies2015 = allGoalies2015[~np.isnan(allGoalies2015)]\n",
    "\n",
    "\n",
    "# Find all the unique goalie IDs from the Home and Away Goalie Ids in the Play By Play Data\n",
    "# Union will drop duplicates\n",
    "allGoalies2016 = np.union1d( pd.unique(pbp2016[\"Away_Goalie_Id\"]), pd.unique(pbp2016[\"Home_Goalie_Id\"]))\n",
    "# Drop the empty fields\n",
    "allGoalies2016 = allGoalies2016[~np.isnan(allGoalies2016)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Goalie Shape 2015\", allGoalies2015.shape)\n",
    "print(\"Goalie Shape 2016\", allGoalies2016.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to drop all goalies from the shift data\n",
    "shift2015 = shift2015[~shift2015[\"Player_Id\"].isin(allGoalies2015)]\n",
    "\n",
    "shift2016 = shift2016[~shift2016[\"Player_Id\"].isin(allGoalies2016)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shifts without Goalies 2015\", shift2015.shape)\n",
    "print(\"Row dropped from 2015: \",  str(shift2015RowNumber - shift2015.shape[0]) , \"Rows Dropped\")\n",
    "print(\"Shifts without Goalies 2016\", shift2016.shape)\n",
    "print(\"Row dropped from 2016: \",  str(shift2016RowNumber - shift2016.shape[0]) , \"Rows Dropped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subset Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset Play by play data to be only goal data for counting later on. \n",
    "goalEvents2015 = pbp2015.loc[pbp2015[\"Event\"]== \"GOAL\", :].copy()\n",
    "# Rename the Play by Play Id to be Goal_Id\n",
    "goalEvents2015.rename(columns={'Pbp_Id': 'Goal_Id'}, inplace=True)\n",
    "# Drop all non-goal columns (Keep the assist columns p2_ID, p3_ID to count points)\n",
    "goalEvents2015.drop(columns=[\"Date\", \n",
    "                             \"Period\", \n",
    "                             \"Event\", \n",
    "                             \"p1_name\", \n",
    "                             \"p2_name\", \n",
    "                             \"p2_ID\", \n",
    "                             \"p3_name\", \n",
    "                             \"p3_ID\", \n",
    "                             \"Away_Goalie\", \n",
    "                             \"Away_Goalie_Id\",  \n",
    "                             \"Home_Goalie\", \n",
    "                             \"Home_Goalie_Id\"], inplace = True)\n",
    "goalEvents2016 = pbp2016.loc[pbp2016[\"Event\"]== \"GOAL\", :].copy()\n",
    "goalEvents2016.rename(columns={'Pbp_Id': 'Goal_Id'}, inplace=True)\n",
    "goalEvents2016.drop(columns=[\"Date\", \n",
    "                             \"Period\", \n",
    "                             \"Event\", \n",
    "                             \"p1_name\", \n",
    "                             \"p2_name\", \n",
    "                             \"p2_ID\", \n",
    "                             \"p3_name\", \n",
    "                             \"p3_ID\", \n",
    "                             \"Away_Goalie\", \n",
    "                             \"Away_Goalie_Id\",  \n",
    "                             \"Home_Goalie\", \n",
    "                             \"Home_Goalie_Id\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Goals in 2015\", goalEvents2015.shape[0])\n",
    "print(\"Goals in 2016\", goalEvents2016.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit the Shifts to the first period\n",
    "firstPeriodShift2015 = shift2015.loc[shift2015[\"Period\"] == 1, :].copy()\n",
    "firstPeriodShift2016 = shift2016.loc[shift2016[\"Period\"] == 1, :].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all the Game Ids\n",
    "gameIds2015 = firstPeriodShift2015[\"Game_Id\"].unique()\n",
    "gameIds2016 = firstPeriodShift2016[\"Game_Id\"].unique()\n",
    "print(\"Games in 2015:\", gameIds2015.shape[0])\n",
    "print(\"Games in 2016:\", gameIds2016.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFirstShift(gameIds, shifts):\n",
    "    #Go through every game\n",
    "    firstShift = []\n",
    "    # For every gameId in the game IDs\n",
    "    for game in gameIds:\n",
    "        # Find all the shifts that game\n",
    "        gameShifts = shifts[(shifts[\"Game_Id\"] == game)]\n",
    "        # Find the first shift for every player_id\n",
    "        # Group by the Player Ids\n",
    "        # Then take out the Shift_Id, Player_Id, Duration and Game_Id fields\n",
    "        # Then take the first instance of that\n",
    "        playerShifts = gameShifts.groupby(\"Player_Id\")[[\"Shift_Id\",\"Game_Id\", \"Player_Id\", \"Duration\"]].first()\n",
    "        # Add on the first shift for all those players\n",
    "        firstShift.append(playerShifts)\n",
    "    return pd.concat(firstShift)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all the first shifts for 2015\n",
    "firstShift2015 = getFirstShift(gameIds2015, firstPeriodShift2015)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstShift2015.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstShift2016 = getFirstShift(gameIds2016, firstPeriodShift2016)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"All Shift Data 2015\")\n",
    "shift2015[[\"Duration\"]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"All Shift Data 2016\")\n",
    "shift2016[[\"Duration\"]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"All First Shift Data 2015\")\n",
    "firstShift2015[[\"Duration\"]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"All First Shift Data 2016\")\n",
    "firstShift2016[[\"Duration\"]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributions\n",
    "Skewness is a measure of asymmetry of a distribution.In a normal distribution, the mean divides the curve symmetrically into two equal parts at the median and the value of skewness is zero. When the value of the skewness is negative, the tail of the distribution is longer towards the left hand side of the curve. When the value of the skewness is positive, the tail of the distribution is longer towards the right hand side of the curve\n",
    "\n",
    "\n",
    "Kurtosis is one of the two measures that quantify shape of a distribution. Kutosis determine the volume of the outlier. Kurtosis describes the peakedness of the distribution, if the distribution is tall and thin it is (Kurtosis > 3). Values with high peakness distribution are near the mean or at the extremes. A flat distribution where the values are moderately spread out. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Player Shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( \"Distribution skew of 2015 Shifts\", shift2015[\"Duration\"].skew())\n",
    "print( \"Distribution peakness of 2015 Shifts\", shift2015[\"Duration\"].kurtosis())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the the skewness being greater than 1 at 1.63, the data is highly skewed. \n",
    "\n",
    "If the distribution is tall and thin it is called a leptokurtic distribution(Kurtosis > 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(shift2015[\"Duration\"], bins= 100, density = True)\n",
    "ax.set_xlabel('Shift Duration (Seconds)')\n",
    "ax.set_ylabel('Probability density')\n",
    "ax.set_title(r'Histogram of 2015 Shift Length')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.xlim(xmin=int(shift2015[[\"Duration\"]].min()), xmax = int(shift2015[[\"Duration\"]].max()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( \"Distribution skew of 2016 Shifts\", shift2016[\"Duration\"].skew())\n",
    "print( \"Distribution peakness of 2016 Shifts\", shift2016[\"Duration\"].kurtosis())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(shift2016[\"Duration\"],bins= 100, density = True)\n",
    "ax.set_xlabel('Shift Duration (Seconds)')\n",
    "ax.set_ylabel('Probability density')\n",
    "ax.set_title(r'Histogram of 2016 Shift Length')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.xlim(xmin=int(shift2016[[\"Duration\"]].min()), xmax = int(shift2016[[\"Duration\"]].max()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( \"Distribution skew of 2015 First Shifts\", firstShift2015[\"Duration\"].skew())\n",
    "print( \"Distribution peakness of 2015 First Shifts\", firstShift2015[\"Duration\"].kurtosis())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(firstShift2015[\"Duration\"],bins= 100, density = True)\n",
    "ax.set_xlabel('Shift Duration (Seconds)')\n",
    "ax.set_ylabel('Probability density')\n",
    "ax.set_title(r'Histogram of 2015 First Shift Length')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.xlim(xmin=int(firstShift2015[[\"Duration\"]].min()), xmax = int(firstShift2015[[\"Duration\"]].max()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( \"Distribution skew of 2016 First Shifts\", firstShift2016[\"Duration\"].skew())\n",
    "print( \"Distribution peakness of 2016 First Shifts\", firstShift2016[\"Duration\"].kurtosis())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(firstShift2016[\"Duration\"],bins = 100, density = True)\n",
    "ax.set_xlabel('Shift Duration (Seconds)')\n",
    "ax.set_ylabel('Probability density')\n",
    "ax.set_title(r'Histogram of 2016 First Shift Length')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.xlim(xmin=int(firstShift2016[[\"Duration\"]].min()), xmax = int(firstShift2016[[\"Duration\"]].max()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier Removal\n",
    "\n",
    "Since my data is right tailed, meaning there are som shifts that are extremely long, they will drag my mean to the right of the median, the middle point of the data. \n",
    "\n",
    "I propose removing any shifts longer than 128 seconds. Although that is double the average shift (44 Seconds) that would be the equal of doubling shifting your best player, which is what gretzky supposedly did. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "withOutliers2015 = shift2015.shape[0]\n",
    "shift2015= shift2015[shift2015[\"Duration\"] < 128.0 ]\n",
    "print(\"All Shifts Rows dropped:\", withOutliers2015 -  shift2015.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "withOutliers2016 = shift2016.shape[0]\n",
    "shift2016 = shift2016[shift2016[\"Duration\"] < 128.0 ]\n",
    "print(\"All Shifts Rows dropped:\", withOutliers2016 -  shift2016.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FSOutliers2015 = firstShift2015.shape[0]\n",
    "firstShift2015= firstShift2015[firstShift2015[\"Duration\"] < 128.0 ]\n",
    "print(\"First Rows dropped:\", FSOutliers2015 -  firstShift2015.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FSOutliers2016 = firstShift2016.shape[0]\n",
    "firstShift2016= firstShift2016[firstShift2016[\"Duration\"] < 128.0 ]\n",
    "print(\"First Rows dropped:\", FSOutliers2016 -  firstShift2016.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( \"Distribution skew of 2015 Shifts\", shift2015[\"Duration\"].skew())\n",
    "print( \"Distribution peakness of 2015 Shifts\", shift2015[\"Duration\"].kurtosis())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We seem to have normalized the data to a relatively acceptable skewness of .59 and a peakness value of 2.24. We don't want to normalize the data to much because we need enough long shifts to represent a double shift and see the shift's affect on the player's game. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(shift2015[\"Duration\"], bins= 100, density = True)\n",
    "ax.set_xlabel('Shift Duration (Seconds)')\n",
    "ax.set_ylabel('Probability density')\n",
    "ax.set_title(r'Histogram of 2015 Shift Length')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.xlim(xmin=int(shift2015[[\"Duration\"]].min()), xmax = int(shift2015[[\"Duration\"]].max()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( \"Distribution skew of 2016 Shifts\", shift2016[\"Duration\"].skew())\n",
    "print( \"Distribution peakness of 2016 Shifts\", shift2016[\"Duration\"].kurtosis())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(shift2016[\"Duration\"],bins= 100, density = True)\n",
    "ax.set_xlabel('Shift Duration (Seconds)')\n",
    "ax.set_ylabel('Probability density')\n",
    "ax.set_title(r'Histogram of 2016 Shift Length')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.xlim(xmin=int(shift2016[[\"Duration\"]].min()), xmax = int(shift2016[[\"Duration\"]].max()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( \"Distribution skew of 2015 First Shifts\", firstShift2015[\"Duration\"].skew())\n",
    "print( \"Distribution peakness of 2015 First Shifts\", firstShift2015[\"Duration\"].kurtosis())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(firstShift2015[\"Duration\"],bins= 100, density = True)\n",
    "ax.set_xlabel('Shift Duration (Seconds)')\n",
    "ax.set_ylabel('Probability density')\n",
    "ax.set_title(r'Histogram of 2015 First Shift Length')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.xlim(xmin=int(firstShift2015[[\"Duration\"]].min()), xmax = int(firstShift2015[[\"Duration\"]].max()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( \"Distribution skew of 2016 First Shifts\", firstShift2016[\"Duration\"].skew())\n",
    "print( \"Distribution peakness of 2016 First Shifts\", firstShift2016[\"Duration\"].kurtosis())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(firstShift2016[\"Duration\"],bins = 100, density = True)\n",
    "ax.set_xlabel('Shift Duration (Seconds)')\n",
    "ax.set_ylabel('Probability density')\n",
    "ax.set_title(r'Histogram of 2016 First Shift Length')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.xlim(xmin=int(firstShift2016[[\"Duration\"]].min()), xmax = int(firstShift2016[[\"Duration\"]].max()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide the average shift\n",
    "avgShift2015 = round(shift2015[\"Duration\"].mean())\n",
    "avgShift2016 = round(shift2016[\"Duration\"].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average Shift 2015:\", avgShift2015)\n",
    "print(\"Average Shift 2016:\", avgShift2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isShiftLong(shifts, avgShift):\n",
    "    category = []\n",
    "    for shift in shifts:\n",
    "        if shift >= avgShift:\n",
    "            category.append('Long')\n",
    "        else:\n",
    "            category.append('Short')\n",
    "    return category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstShift2015[\"Shift_Category\"] = np.where(firstShift2015[\"Duration\"] > avgShift2015, 'Long', 'Short')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstShift2015.reset_index(drop = True, inplace= True)\n",
    "firstShift2015.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstShift2016[\"Shift_Category\"] = np.where(firstShift2016[\"Duration\"] > avgShift2016, 'Long', 'Short')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstShift2016.reset_index(drop = True, inplace= True)\n",
    "firstShift2016.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for that game and for that player, take the sum of goals. Make another DF that will have the sum of the goals, the player and game id, will then have shit_category attached. Afterwards we will show the difference between the two categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "playerGoalsPer2015 = goalEvents2015.groupby([\"Game_Id\", \"p1_ID\"]).count().reset_index()\n",
    "playerGoalsPer2015.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedGame2015 = firstShift2015.merge(playerGoalsPer2015, how='left', left_on=[\"Game_Id\",'Player_Id'], right_on = [\"Game_Id\",\"p1_ID\"])\n",
    "mergedGame2015.fillna(0, inplace=True)\n",
    "mergedGame2015.drop(columns = [\"p1_ID\"], inplace = True)\n",
    "mergedGame2015.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playerGoalsPer2016 = goalEvents2016.groupby([\"Game_Id\", \"p1_ID\"]).count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedGame2016 = firstShift2016.merge(playerGoalsPer2016, how='left', left_on=[\"Game_Id\",'Player_Id'], right_on = [\"Game_Id\",\"p1_ID\"])\n",
    "mergedGame2016.fillna(0, inplace=True)\n",
    "mergedGame2016.drop(columns = [\"p1_ID\"], inplace = True)\n",
    "mergedGame2016.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to reject my null hypothesis I will need to have sufficent evidence to to say that outcome I am observing is not due to chance. That the year 2015 or 2016 is not a random occurence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedGame2015.groupby(\"Shift_Category\")[\"Goal_Id\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped2015 = mergedGame2015.groupby(\"Shift_Category\")[\"Goal_Id\"].mean()\n",
    "grouped2015Short = grouped2015[1]\n",
    "grouped2015Long = grouped2015[0]\n",
    "grouped2015Diff = grouped2015Long - grouped2015Short\n",
    "print(grouped2015)\n",
    "print(grouped2015Diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedGame2016.groupby(\"Shift_Category\")[\"Goal_Id\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped2016 = mergedGame2016.groupby(\"Shift_Category\")[\"Goal_Id\"].mean()\n",
    "grouped2016Short = grouped2016[1]\n",
    "grouped2016Long = grouped2016[0]\n",
    "grouped2016Diff = grouped2016Long - grouped2016Short\n",
    "print(grouped2016)\n",
    "print(grouped2016Diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just looking at the Total Count of Goals and Mean of Goals for 2015 and 2016 the first shift duration does not have an effect on the number of goals on average. It actually looks like the shorter the shift the more goals players score throughout the game. \n",
    "\n",
    "\n",
    "Next we will look to see if shift duration and goals/game average is correlated.\n",
    "\n",
    "Finally, we will look to see what we are observing if it is trully accurate or up to random chance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedGame2015.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedGame2016.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goals/Game average is not corralted with First Shift Duration (Correlation Coefficient: -0.00944/-0.01100)\n",
    "\n",
    "It does not appear that First Shift Duration has any relationship with Goals/Game average. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final thoughts:\n",
    "\n",
    "- I wonder if we decided the shift category on the median and instead of the mean.\n",
    "\n",
    "- I wonder if the first shift duration has anything to do with the point totals, not just goals.\n",
    "\n",
    "- I wonder if the second shift should be long"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to see over thousands of seasons how much the Goals/Game average would differ for our \"Long\" first shift group versus our \"Short\" first shift group. \n",
    "\n",
    "For 2015 the Goals/Game average would differ for our \"Long\" first shift group versus our \"Short\" first shift group was -0.003 Goals per game. Meanings on average the Short first shift group scored .003 more goals per games than the Long first shift group.\n",
    "\n",
    "For 2016 the Goals/Game average would differ for our \"Long\" first shift group versus our \"Short\" first shift group was -0.005 Goals per game. Meanings on average the Short first shift group scored .005 more goals per games than the Long first shift group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap\n",
    "\n",
    "We will want to take a sample of the first shift group (sample of players first shifts), and match it up with the goal data for those games and players. We will then take the means of the two groups, Long/Short and then show the difference for 1000 samples. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Size\n",
    "Lets determine our N, this would be our sample size for First Shift Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a good sample size is around 10% of the population\n",
    "## But that is too large. It is greater than 1000\n",
    "rows = firstShift2015.shape[0]\n",
    "print(\"Population of First Shifts\", rows)\n",
    "print(\"10% of First Shift Rows\", rows * .1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your confidence level corresponds to something called a \"z-score.\" A z-score is a value that indicates the placement of your raw score (meaning the percent of your confidence level) in any number of standard deviations below or above the population mean.\n",
    "\n",
    "Z-scores for the most common confidence intervals are:\n",
    "\n",
    "90% = 2.576\n",
    "95% = 1.96\n",
    "99% = 2.576"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead we will use a calculated sample size.\n",
    "## Our intended level of confidence will be 95%\n",
    "## where Z is the Z-score corresponding to your desired confidence level \n",
    "## p is the estimated proportion of the population with a certain characteristic\n",
    "## E is the maximum error you are willing to tolerate in your estimate.\n",
    "## N population size\n",
    "\n",
    "Z = 1.96\n",
    "E = 0.05\n",
    "N = rows\n",
    "p = .05\n",
    "n = round(((Z**2 * p * (1-p))/ E**2)/(1 + ((Z**2 * p *(1-p))/((E**2) * N))))\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = firstShift2015.sample( n = n, replace = True)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleMerged2015 = sample.merge(playerGoalsPer2015, \n",
    "                                    how='left', \n",
    "                                    left_on=[\"Game_Id\",'Player_Id'], \n",
    "                                    right_on = [\"Game_Id\",\"p1_ID\"])\n",
    "sampleMerged2015.fillna(0, inplace=True)\n",
    "sampleMerged2015.drop(columns=[\"p1_ID\"], inplace = True)\n",
    "sampleMerged2015.head(36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleGrouped2015 = sampleMerged2015.groupby(\"Shift_Category\")[\"Goal_Id\"].mean()\n",
    "sampleGrouped2015Short = sampleGrouped2015[1]\n",
    "sampleGrouped2015Long = sampleGrouped2015[0]\n",
    "sampleGrouped2015Diff = sampleGrouped2015Long - sampleGrouped2015Short\n",
    "print(sampleGrouped2015)\n",
    "print(sampleGrouped2015Diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find here in this sample that the short shift group scored on average .018 more goals per game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def goalsPerGameDiffBoot(shifts, goalsGame, sampleSize, iterations):\n",
    "    goalDiffs = []\n",
    "    for i in range(iterations):\n",
    "        sample = shifts.sample(n = sampleSize, replace = True)\n",
    "        sampleMerged = sample.merge(goalsGame, \n",
    "                                    how='left', \n",
    "                                    left_on=[\"Game_Id\",'Player_Id'], \n",
    "                                    right_on = [\"Game_Id\",\"p1_ID\"])\n",
    "        sampleMerged.fillna(0, inplace=True)\n",
    "        sampleGrouped = sampleMerged.groupby(\"Shift_Category\")[\"Goal_Id\"].mean()\n",
    "        sampleGroupedShort = sampleGrouped[1]\n",
    "        sampleGroupedLong = sampleGrouped[0]\n",
    "        sampleGroupedDiff = sampleGroupedLong - sampleGroupedShort\n",
    "        goalDiffs.append(sampleGroupedDiff)\n",
    "        \n",
    "    return goalDiffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffBootData1000 = goalsPerGameDiffBoot(shifts = firstShift2015, \n",
    "                                    goalsGame = goalEvents2015, \n",
    "                                    sampleSize = n, \n",
    "                                    iterations = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(diffBootData1000, bins=20, color='blue', alpha=0.5)\n",
    "plt.xlabel('Goal Average Differential')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of 1000 iterations of Goal Differential')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffBootData10000 = goalsPerGameDiffBoot(shifts = firstShift2015, \n",
    "                                    goalsGame = goalEvents2015, \n",
    "                                    sampleSize = n, \n",
    "                                    iterations = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(diffBootData10000, bins=20, color='blue', alpha=0.5)\n",
    "plt.xlabel('Goal Average Differential')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of 10,000 iterations of Goal Differential')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
